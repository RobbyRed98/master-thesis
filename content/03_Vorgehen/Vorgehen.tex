\chapter{Vorgehen}
\label{vorgehen}
Im Rahmen dieses Kapitels werden die Untersuchungs- und Analyse-Methoden erläutert, die für die Evaluation von Db2 Graph herangezogen wurden. 

\section{Performance-Analyse}
\label{vorgehen:performance-analyse}
Dieser Abschnitt beschreibt, welches Vorgehen für die Performance-Analyse von Db2 Graph gewählt wurde. Dabei gilt es zu erwähnen, dass sich das Vorgehen grob an den Messungen in \cite{sigmod_tian}. Darin wurden Db2 Graph und zwei weitere Graphdatenbanksysteme miteinander bezüglich der Linkbench-Performance verglichen \cite{sigmod_tian}. Allerdings muss darauf hingewiesen werden, dass die Messungen dieser Arbeit und in \cite{sigmod_tian} nicht vergleichbar sind. Weder die Db2 Graph Version(en), die Benchmark-Adapter und der für die Messungen eingesetzte Datensatz überschneiden sich. Der Benchmark Linkbench und die Metriken Latenz und Durchsatz wurden hingegen aus \cite{sigmod_tian} in diese Arbeit übernommen. 

\subsection{Benchmark}
Der Benchmark Linkbench wurde nicht ausschließlich als Mittel für die Performance-Analyse gewählt, weil dieser auch in \cite{sigmod_tian} eingesetzt wurde. 

Stattdessen wurde der Benchmark aus folgenden Gründen ausgesucht:
\begin{itemize}
    \item Es handelt sich bei Linkbench um einen Benchmark für Graph-Daten.
    \item Der Workload des Benchmarks ist einer realen Arbeitslast nachempfunden, auch wenn er sich hauptsächlich auf OLTP-Operationen beschränkt, siehe \autoref{linkbench:operationen}. 
    \item Auf der Basis der elementaren Graph-Operationen lässt sich bereits eine Einordnung der Performance von Db2 Graph oder Systemen vornehmen. 
    \item Linkbench ist flexibel konfigurier- und erweiterbar, siehe \autoref{linkbench}. 
    \item Der Aufwand für die Implementierung eines Adapters für Db2 Graph wurde als im Rahmen dieser Arbeit möglich eingeschätzt.
\end{itemize}
Bevor der Linkbench-Benchmark für die Performance-Analyse im Rahmen dieser Arbeit gewählt wurde, wurde auch der SNB-Benchmark als möglich Alternative gehandelt. Bei diesem  handelt es sich um einen deutlich neueren Benchmark für Graph-Daten als Linkbench \cite{snb_paper}. Dieser wurde vom LDBC-Projekt initiiert und entwickelt \cite{snb_paper}. Der Benchmark versucht dabei sowohl OLTP- als auch OLAP-Workloads abzubilden, anders als Linkbench der hauptsächlich OLTP-Operationen abdeckt \cite{snb_paper}. Die Wahl viel allerdings wie zuvor beschrieben auf Linkbench, da der Aufwand für die Anbindung von Db2 Graph an diesen Benchmark als geringer eingestuft wurde.  

\subsection{Vergleich}
Um die Linkbench-Ergebnisse von Db2 Graph später besser einordnen zu können, werden die Messergebnisse im Rahmen dieser Analyse mit denen des Datenbanksystems Neo4j verglichen. Dieses Vorgehen wurde hierbei gewählt, da es sich bei Neo4j um ein bekanntes, natives Graph-Datenbankmanagementsystem handelt. Dadurch stellt Neo4j einen aussagekräftige Referenz dar, an der Db2 Graph gemessen werden kann. 

\subsection{Implementierung}
Um Neo4j, Db2 Graph Beta 3 und Db2 Graph V11.5.6.0 an Linkbench anzubinden wurden im Rahmen dieser Arbeit vier verschiedenen Adapter implementiert. Zu diesen Adaptern gehören:
\begin{itemize}
    \item \texttt{Neo4j}-Adapter für Neo4j,
    \item \texttt{Db2GraphOld}-Adapter für Db2 Graph Beta 3, 
    \item \texttt{Db2Graph}-Adapter für Db2 Graph V11.5.6.0 und
    \item \texttt{Db2}-Adapter -- wird hauptsächlich von den Adaptern für Db2 Graph als Basis genutzt.
\end{itemize}
Weitere Details bezüglich der Implementierung werden in \todo{Referenz für Implementierungskapitel} erläutert.

\subsection{Operationen}
Für die Performance-Analyse der Datenbanksysteme werden im Rahmen dieser Arbeit die folgenden Operationen von Linkbench herangezogen:
\begin{itemize}
    \item \texttt{getNode},
    \item \texttt{getLink},
    \item \texttt{countLink} und
    \item \texttt{getLinkList}.
\end{itemize}
Die Auswahl wurde getroffen, da Db2 Graph Beta 3 und v11.5.6.0 ausschließen lesende-Operationen unterstützen. Bei allen anderen Operationen die in \autoref{linkbench:operationen} aufgeführt werden handelt es sich jedoch um schreibende Operationen. Daher muss auf diese verzichtet werden. 

In \autoref{src:gremlin_queries} werden die Gremlin-Queries aufgeführt, die für das Benchmarking von Db2 Graph Beta 3 und Db2 Graph V11.5.6.0 eingesetzt wurden. 
\begin{lstlisting}[label=src:gremlin_queries,caption={ Gremlin Queries (regulär)},language=Java]
/* getNode */
g.V()
 .hasLabel("NODETABLE")
 .has("ID", <NODE_ID>);

/* getLink */
g.E()
 .hasLabel("LINKTABLE")
 .has("LINK_TYPE", <LINK_TYPE>)
 .has("ID1", <NODE_ID1>)
 .has("ID2", P.within(<NODE_ID2s>))

/* countLinks */
g.V()
 .hasLabel("NODETABLE")
 .has("ID", <NODE_ID>)
 .outE("LINKTABLE")
 .has("LINK_TYPE", <LINK_TYPE>)
 .count()

/* getLinkList */
g.V()
 .hasLabel("NODETABLE")
 .has("ID", <NODE_ID1>)
 .outE("LINKTABLE")
 .has("LINK_TYPE", <LINK_TYPE>)
 .limit(<LIMIT>);
\end{lstlisting}

Für das Benchmarking von Neo4j wurden hingegen die  Cypher-Queries in \autoref{src:cypher_queries}. Neo4j unterstützt zwar auch Gremlin als Abfragesprache \cite{gdbms}. Allerdings handelt es sich bei Cypher um die bevorzugte Abfragesprache zur Interaktion mit Neo4j \cite{gdbms}.

\begin{lstlisting}[label=src:cypher_queries,caption={Cypher Queries (regulär)},language=CQL]
/* getNode */
MATCH (n:node{id: $id}) 
RETURN n.id AS ID, n.type AS TYPE, 
    n.version AS VERSION, n.time AS TIME, 
    n.data AS DATA

/* getLink */
MATCH (n1:node{id: $id1})-[l:link{link_type: $link_type}]->(n2:node) 
WHERE n2.id IN $id2s 
RETURN n1.id AS ID1, n2.id AS ID2, 
    l.link_type AS LINK_TYPE, 
    l.visibility AS VISIBILITY, 
    l.data AS DATA, l.time AS TIME, 
    l.version AS VERSION

/* countLinks */
MATCH (:node{id: $id1})-
    [l:link{link_type: $link_type}]->
    (:node) 
RETURN COUNT(l) AS COUNT

/* getLinkList */
MATCH (n1:node{id: $id1})-
    [l:link{link_type: $link_type}]->
    (n2:node) 
RETURN n1.id AS ID1, n2.id AS ID2, 
    l.link_type AS LINK_TYPE, 
    l.visibility AS VISIBILITY, 
    l.data AS DATA, l.time AS TIME, 
    l.version AS VERSION 
LIMIT $limit
\end{lstlisting}

Im Zuge der Performance-Analyse der Datenbanksysteme werden allerdings bei Messungen mit real-verteilten Datensätzen vier verschiedene Varianten der \texttt{getLinkList}-Operation eingesetzt. Darauf wird in im Detail eingegangen \autoref{analyse:parameter}.

\subsection{Metriken}
Bei den Messungen im Rahmen der Arbeit werden die folgenden Metriken herangezogen: 

\begin{itemize}
    \item Latenz und 
    \item Durchsatz.
\end{itemize}

Der Begriff Latenz bezeichnet dabei den Zeitraum zwischen dem Abschicken einer Anfrage an ein Datenbanksystem und dem Eintreffen der Antwort auf die Anfrage. Alternative könnte die Latenz auch als Verarbeitungszeit betrachtet werden. 

Unter der Metrik Durchsatz wird dabei erfasst, wie viele Operationen pro Sekunde im Durchschnitt während einer Messung durchgeführt werden. 

Darüber hinaus werden während jeder Messungen die Betriebssystemstatistiken erfasst. NMON zeichnet dabei einmal pro Minute einen Datenpunkt auf. Diese Statistiken werden hierbei nicht als eine weitere Metrik betrachtet. Die registrierten Daten können allerdings bei der Auswertung der Ergebnisse ergänzend hinzugezogen werden.

\subsection{Parameter}
\label{analyse:parameter}
Die Messungen die im Rahmen dieser Arbeit durchgeführt werden, können anhand von zwei Hauptparametern unterschieden werden:
\begin{itemize}
    \item die Verteilung / Struktur der Datensätze und 
    \item die Größe der Datensätze. 
\end{itemize}
Diese beiden Messparameter spielen hierbei im Kontext aller Messungen eine wichtige Rolle. 

Darüber hinaus gibt es noch die zwei Nebenparameter:
\begin{itemize}
    \item Ergebnismenge und 
    \item Query-Stil. 
\end{itemize}
Diese spielen hierbei entweder bei Messungen mit real- oder mit konstant-verteilten Datensätzen eine Rolle.  

\subsubsection{Verteilung}
Bei der Struktur der Datensätze kann zwischen den beiden folgenden Verteilungen unterschieden werden: 

\begin{itemize}
    \item \textit{konstante Verteilung}\\
    Hierbei besitzt jeder Knoten im Datensatz exakt dieselbe Anzahl an Kanten (Links) wie jeder andere Knoten. Im Rahmen dieser Arbeit wurde bei allen Messungen immer eine konstante 10er-Verteilung gewählt. Dies bedeutet das jeder Knoten genau 10 Kanten aufweist.  
    \item \textit{reale Verteilung}\\
    Hierbei ist die Verteilung von Kanten (Links) auf Knoten einer realen Verteilung eines Social-Graphs nachempfunden. Die Anzahl der Kanten, über die ein Knoten verfügt, bewegt sich dabei bei allen Messungen die in dieser Arbeit durchgeführt werden zwischen 2 und ca. 5.000.000. Dabei gibt es sehr viele Knoten mit einer geringen Anzahl an Kanten wie zwei und einzelne Knoten die mehr als 1.000.000 Kanten aufweisen. 
\end{itemize}

Die real-Verteilung wurde hierbei für die Messungen gewählt, da sie eine realitätsnahe Zusammensetzung eines Social-Graphs aufweist. Die Messergebnisse lassen somit Schlüsse darauf zu, wie sich das System bei solchen Workloads in der Praxis verhalten würde.

Die konstante Verteilung wurde entgegen der real-Verteilung nicht aufgrund ihrer Praxis-nähe für die Messungen ausgewählt. Stattdessen wurde Sie für die Messungen herangezogen, da Db2 Graph Beta 3 bei ersten Versuchen Schwierigkeiten mit einer hohen Kantenzahl in real-Verteilten Datensätzen aufwies. Das Benchmarking der \texttt{getLinkList}-Operation verursachte hierbei früher oder später einen beinahe Stillstand des Benchmark-Durchlaufs. 

Dieses Verhalten kann hierbei damit begründet werden, dass sich Db2 Graph Beta 3 damit schwertut, mit großen Ergebnismengen von über 100.000 Kanten je Knoten zu arbeiten. Darüber hinaus kann dieses Problem von Db2 Graph Beta 3 mit real-verteilten Datensätzen auch nicht durch die Begrenzung der Ergebnismenge im Rahmen der Gremlin-Query gelöst werden. Schließlich beherrscht Db2 Graph Beta 3 die Optimierungstechnik \textit{Limit Pushdown} nicht, siehe \autoref{db2graph:optimierung}. 

Aufgrund dessen und da es nachvollziehbarer Weise nicht zielführend wäre, die maximale Kanten auf Knoten Verteilung eines real-verteilten Datensatzes zu verändern, wurde auch entschieden, konstant-verteilte Datensätze als Teil der Messungen mit aufzunehmen. Schließlich ergibt sich dadurch die Möglichkeit Messergebnisse für Db2 Graph Beta 3 zu erzielen und diese mit V11.5.6.0 und Neo4j zu vergleichen. Allerdings nur unter der Voraussetzung, dass eine kleine konstante Verteilung gewählt wird, wie die konstante 10er-Verteilung. 

Außerdem gilt es hierbei noch anzumerken, dass es keine Messungen von Db2 Graph Beta 3 und real-verteilten Datensätzen im Rahmen dieser Arbeit erfolgen. Da des zuvor angesprochenen Problems von Db2 Graph Beta 3 mit derart verteilten Datensätzen.

\subsubsection{Größe}
Dieser Hauptparameter wurde dabei für die Messungen gewählt, um herauszufinden, wie sich die Datenbanksysteme beim Umgang mit kleineren (Linkbench-10M) und größeren (Linkbench-100M) Datensätzen verhalten. 

Hierbei wird in dieser Arbeit zwischen Datensätzen mit der Knoten Anzahl 10 Millionen und 100 Millionen unterschieden. Angelehnt an \cite{sigmod_tian} werden die Messergebnisse für die verschiedenen Knotenzahlen hier auch als:
\begin{itemize}
    \item Linkbench-10M für 10 Millionen Knoten und 
    \item Linkbench-100M für 100 Millionen Knoten bezeichnet.
\end{itemize}
Dadurch fällt die Unterscheidung zwischen den beiden Größenordnungen leichter. 

Dabei muss allerdings im Auge behalten werden, dass sich die Größe der Datenmengen je nach Verteilung eines Datensatzes weiterhin unterscheiden kann. Schließlich verfügen die Datensätze bei gleicher Knoten Anzahl über unterschiedlich viele Kanten, siehe \autoref{tab:kanten_anzahl}. So weisen in \autoref{tab:kanten_anzahl} konstant verteilte Datensätze fast die doppelte Anzahl an Kanten auf, wie real-verteilte Datensätze, bei der identischen Konfiguration Größen-Parameters. 

\begin{table}[ht]
    \centering
    \begin{tabular}{l|r|r}
    \hline
    \rowcolor[HTML]{EFEFEF} 
    \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\textbf{Verteilung}} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\textbf{Linkbench-10M}} & \multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}\textbf{Linkbench-100M}} \\ \hline
    real & ca. 53.000.000 Kanten & ca. 530.000.000 Kanten \\
    konstant & 100.000.000 Kanten & 1.000.000.000 Kanten \\ \hline
    \end{tabular}
    \caption{Übersicht Linkbench Kantenanzahl}
    \label{tab:kanten_anzahl}
    \vspace{1em}
    \textit{}
\end{table}

Aufgrund dessen sollte auch später vom Vergleich der Messergebnisse zwischen den unterschiedlich verteilten Datensätzen bei Linkbench-10M und Linkbench-100M abgesehen werden.

\subsubsection{Ergebnismenge}
Dieser Parameter regelt bei den Messungen mit real-verteilten Datensätzen, wie groß die Ergebnismenge bei der \texttt{getLinkList}-Operation maximal werden kann. Konkret legt der Parameter dabei fest, wie viele Kanten maximal Teil der Ergebnismenge einer \texttt{getLinkList}-Operation sein können.

Durch die Variation des Parameters kann hierbei ermittelt werden, wie sich die Größe der Ergebnismengen, auf die Performance der Datenbanksysteme auswirkt. 

Die Beschränkung der Ergebnismenge wird dabei in der Linkbench-Workload-Konfiguration vorgenommen. Für die Konfiguration muss dort der Wert für \texttt{range\_limit} angepasst werden. 

Dieser Parameter wird dabei als Bestandteil aller Messungen bei real-verteilten Datensätzen herangezogen. Schließlich sind bei diesen auch größere Ergebnismengen möglich. Das Limit der Ergebnismenge bei der \texttt{getLinkList}-Operation variiert bei diesen Messungen immer zwischen: 
\begin{itemize}
    \item 100,
    \item 1.000,
    \item 10.000 und
    \item 100.000.
\end{itemize}

So werden bei den Messungen mit Bezug zu real-verteilten Datensätzen statt der vier regulären, die folgenden sieben Operationen gebenchmarkt:
\begin{itemize}
    \item \texttt{getNode},
    \item \texttt{getLink},
    \item \texttt{countLink},
    \item \texttt{getLinkList(100)},
    \item \texttt{getLinkList(1.000)},
    \item \texttt{getLinkList(10.000)} und
    \item \texttt{getLinkList(100.000)}.
\end{itemize}

Der Wert in der Klammer bei der \texttt{getLinkList}-Operation gibt dabei das Limit für die Ergebnismenge an. So nehmen die Platzhalter \texttt{<LIMIT>} und \texttt{\$limit}
in \autoref{src:gremlin_queries} und \autoref{src:cypher_queries} bei der \texttt{getLinkList}-Operation die zuvor aufgeführten Werte an, im Rahmen der Messungen.

\subsubsection{Query-Stil}
Der Query-Stil stellt einen weiteren Parameter Nebenparameter dar. Dabei wird zwischen sogenannten regulären Queries und ID-Queries unterschieden. 

Bei den regulären Queries handelt es sich um die Anfragen, die bereits in \autoref{src:gremlin_queries} und \autoref{src:cypher_queries} aufgeführt wurden. Die Queries werden als reguläre Queries bezeichnet, da sie nahezu Bestandteil aller Messreihen sind, siehe \todo{Referenz Messreihen}. 

Die sogenannten ID-Queries unterscheiden sich bezüglich der Logik der Abfrage nur geringfügig von sogenannten regulären Queries. Allerdings werden die Gremlin-Queries anders formuliert als bei den regulären Queries. So nutzen die Gremlin ID-Queries in \autoref{src:gremlin_id_queries} eine Gremlin-ID -- ähnlich der \texttt{vid} oder \texttt{eid} von Db2 Graph in \autoref{db2graph:funktionsweise} -- um einen bestimmten Knoten oder Kante direkt im ersten Schritt herauszufiltern. Dies ist in \autoref{src:gremlin_id_queries} daran erkennbar, dass dort parametrisierte Versionen der Steps \texttt{V()} und \texttt{E()} zum Einsatz kommen. Dabei wird zu Beginn auf die für die regulären Queries typischen \texttt{has}- und \texttt{hasLabel}-Steps verzichtet.

\begin{lstlisting}[label=src:gremlin_id_queries,caption={Gremlin ID-Queries},language=Java]
/* getNode */
g.V(["NODETABLE",<NODE_ID>]);

/* getLink */
g.E(["LINKTABLE", <NODE_ID1>, <NODE_ID2>, <LINK_TYPE>])

/* countLinks */
g.V(["NODETABLE",<NODE_ID1>])
 .outE("LINKTABLE")
 .has("LINK_TYPE", <LINK_TYPE>)

/* getLinkList */
g.V(["NODETABLE",<NODE_ID1>])
 .outE("LINKTABLE")
 .has("LINK_TYPE",  <LINK_TYPE>)
 .limit(<LIMIT>)
\end{lstlisting}

Die Logik zwischen den regulären und ID-Queries unterscheidet sich, wie zuvor erwähnt lediglich geringfügig. Dies beutet das alle Queries dieselben Informationen abfragen, außer bei der \texttt{getLink}-Operation. Während bei dieser Operationen bei den regulären Queries eine Menge an IDs (\texttt{<NODE\_ID2s>}) für den Endknoten genutzt werden, so wird bei den ID-Queries ausschließlich eine ID (<NODE\_ID2>) herangezogen. 

Aufgrund dessen und da der Hauptunterschied zwischen den Query-Stilen den Aufbau der Gremlin-Queries betrifft, muss bei den Cypher ID-Queries lediglich die \texttt{getLink}-Operation wie in \autoref{src:cypher_id_queries} dargestellt
angepasst werden. Dies ist notwendig, um sicherzustellen, dass die Gremlin und Cypher ID-Queries dieselbe Abfragelogik aufweisen und somit dieselben Informationen abfragen. 
\begin{lstlisting}[label=src:cypher_id_queries,caption={Cypher ID-Queries},language=CQL]
/* getLink */
MATCH (n1:node{id: $id1})-[l:link{link_type: $link_type}]->(n2:node{id: $id2}) 
RETURN n1.id AS ID1, n2.id AS ID2, 
    l.link_type AS LINK_TYPE, 
    l.visibility AS VISIBILITY, 
    l.data AS DATA, l.time AS TIME, 
    l.version AS VERSION,
\end{lstlisting}

\subsection{Umgebung}
Für alle Messungen, die Teil der Performance-Analyse sind, wird im Rahmen der Arbeit derselbe Server herangezogen. Bei diesem handelt es sich um einen Ubuntu-Server 20.04.2 LTS mit folgenden Charakteristika:
\begin{itemize}
    \item 32 CPUs (AMD EPYC 7502P), 
    \item 256 GB Arbeitsspeicher,
    \item 500 GB SSD-Hauptspeicher,
    \item \texttt{ext4} als Dateisystem und 
    \item dem Linux-Kernel \texttt{5.4.0-77-generic}.
\end{itemize}
Des Weiteren gilt es dabei herauszustellen, dass die folgenden Datenbanksysteme während Messungen alle als Docker-Container betrieben werden: 
\begin{itemize}
    \item Db2,
    \item Db2 Graph Beta 3,
    \item Db2 Graph V11.5.6.0 und 
    \item Neo4j. 
\end{itemize}
Jedes dieser Systeme wird in einem eigenen Container betrieben. 

\subsection{Datenbanksysteme}
Im Rahmen der Performance-Analyse werden Messungen mit den folgenden Datenbanksystemen durchgeführt: 
\begin{itemize}
    \item Db2 Graph Beta 3 (+ Db2),
    \item Db2 Graph V11.5.6.0 (+ Db2) und
    \item Neo4j.
\end{itemize}
Die Konfiguration dieser Datenbanksysteme wird in den folgenden Unterabschnitten genauer beschrieben. 

\subsubsection{Db2}
Die beiden Db2 Graph Versionen verwenden im Rahmen der Performance-Analyse bei allen Messungen dieselbe Db2 Instanz. Dadurch wird gewährleistet, dass beide auf ein relationales Datenbankmanagementsystem zugreifen, das sich nicht in der Konfiguration zwischen den Db2 Graph Versionen unterscheidet. Außerdem können somit beide Db2 Graph Versionen auf Basis eines identischen Datensatzes operieren. Auf diese Weise kann eine Verzerrung der Messergebnisse vermieden werden und beide Versionen von Db2 Graph arbeiten während des Benchmarking unter denselben Voraussetzungen.

\subsubsection{Db2 Graph}
Die Version Beta 3 und V11.5.6.0 von Db2 Graph verfügen im Rahmen der Performance-Analyse eine vergleichbare Konfiguration. Lediglich die in V11.5.6.0 neu eingeführte \texttt{db2graph-server.yaml} und \texttt{db2graph-internal.yaml} sorgen dafür, dass es Konfigurationsunterschiede zwischen beiden Versionen gibt. Auf diese beiden Konfigurationen wird allerdings nicht näher eingegangen. Schließlich wurden die beiden Konfigurationen nicht für die Messungen angepasst. Somit wird im Rahmen der Performance-Analyse die mit Db2 Graph V11.5.6.0 ausgelieferte Standard-Konfiguration von \texttt{db2graph-server.yaml} und \texttt{db2graph-internal.yaml} her\-angezogen. 

Die \texttt{gremlin-server.yaml} Konfiguration sowie die Ressourcen-Parameter des Gremlin-Servers von Db2 Graph Beta 3 und V11.5.6.0 wurde beide allerdings gleichermaßen für die Messungen angepasst. Unter diese Anpassungen fallen:
\begin{itemize}
    \item \textit{Gremlin-Memory}\\
    Dieser Ressourcen-Parameter legt fest wie viel Memory der Gremlin-Server des TinkerPop-Stacks im maximal Fall nutzen kann. Der Standard-Wert beträgt hier bei beiden Db2 Graph Versionen normalerweise 4 GB. Um eine möglichst hohe Performance mit beiden Db2 Graph Versionen zu erzielen wurde das Memory-Limit für den Gremlin-Server im Rahmen der Messungen allerdings auf 64 GB angehoben. 
    \item \textit{Thread-Pool-Worker}\\
    Der Wert für Thread-Pool-Worker regelt, wie viele Threads für die Verarbeitung von nicht-blockenden Operationen im Gremlin-Server bereitstehen \cite{tinkerpop_2020}. Der Wert ist dabei normalerweise auf 0 gesetzt, was zur Folge hat, das die Anzahl von verfügbaren Prozessoren herangezogen wird \cite{tinkerpop_2020}. Dies hätte im Rahmen der Messumgebung zur Folge, dass die Thread-Pool-Worker standardmäßig auf 32 gesetzt werden würden. 
    
    Um eine möglichst hohe Performance für die Db2 Graph Versionen bei den Messungen zu gewährleisten, wurde der Wert allerdings auf 128 erhöht. Da es dadurch den Gremlin-Server dahingehen unterstützt, große Lasten besser zu verarbeiten. So ist es dem Gremlin-Server dadurch möglich 50 oder 100 Anfragen, die von den entsprechenden Linkbench-Threads während des Benchmarking gesendet werden, auf einmal zu bearbeiten. 
    \item \textit{Gremlin-Pool}\\
    Der Wert für den Gremlin-Pool spezifiziert, wie viele Threads dem Gremlin-Server für die Verarbeitung von blockenden Operationen zur Verfügung stehen \cite{tinkerpop_2020}. Ähnlich wie Thread-Pool-Worker zieht er in der Standard-Konfiguration die verfügbare Prozessoranzahl (32) heran \cite{tinkerpop_2020}. Um eine höhere Performance zu erreichen, wurde er allerdings ebenfalls auf 128 erhöht. 
    
    Die Erhöhung wurde hierbei allerdings lediglich als eine Art Vorsichtsmaßnahme durchgeführt. Schließlich unterstützt Db2 Graph lediglich lesende Queries. Dies hat zur Folge, dass der Gremlin-Server eigentlich nicht auf blockende Operationen zurückgreifen sollte. Allerdings ist nicht bekannt, ob Db2 Graph in der Praxis wirklich nur auf nicht-blockende Operationen zurückgreift. Daher wurde der Wert des Gremlin-Pools analog zu Thread-Pool-Worker angehoben. 
\end{itemize}

\subsection{Messreihen}
Die im Rahmen dieser Arbeit durchgeführten Messungen werden auf Basis einer bestimmten Konfiguration der Parameter aus \autoref{analyse:parameter} in Messreihen eingeteilt. 